<!DOCTYPE html>
<html lang="vi">
<head>
  <meta charset="UTF-8">
  <title>Chá»n ngÆ°á»i tráº£ bÃ i</title>
  <script defer src="https://cdn.jsdelivr.net/npm/face-api.js"></script>
  <style>
    body {
      font-family: Arial, sans-serif;
      text-align: center;
      background-color: #f2f2f2;
    }
    video {
      border: 2px solid #333;
      margin-top: 10px;
    }
    canvas {
      position: absolute;
      z-index: 10;
    }
    #startBtn {
      margin-top: 20px;
      padding: 10px 20px;
      font-size: 16px;
      cursor: pointer;
    }
    .face-image {
      border: 2px solid red;
      margin-top: 20px;
    }
  </style>
</head>
<body>
  <h1>ğŸ¯ TrÃ² chÆ¡i chá»n ngÆ°á»i tráº£ bÃ i báº±ng webcam</h1>
  <p>ğŸ‘‰ Nháº¥n <b>Enter</b> Ä‘á»ƒ chá»n ngáº«u nhiÃªn vÃ  chá»¥p khuÃ´n máº·t</p>
  <button id="startBtn">ğŸ“· Báº¯t Ä‘áº§u nháº­n diá»‡n</button><br>
  <video id="video" width="720" height="560" autoplay muted></video>

  <script>
    const video = document.getElementById('video');
    const startBtn = document.getElementById('startBtn');

    async function setupCamera() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: true });
        video.srcObject = stream;
        return new Promise((resolve) => {
          video.onloadedmetadata = () => resolve(video);
        });
      } catch (err) {
        alert("âš ï¸ KhÃ´ng Ä‘Æ°á»£c cáº¥p quyá»n dÃ¹ng webcam!");
        console.error(err);
      }
    }

    async function startRecognition() {
      await faceapi.nets.tinyFaceDetector.loadFromUri('/models');
      await faceapi.nets.faceLandmark68Net.loadFromUri('/models');
      await faceapi.nets.faceRecognitionNet.loadFromUri('/models');

      const canvas = faceapi.createCanvasFromMedia(video);
      canvas.id = 'overlay';
      canvas.style.position = 'absolute';
      canvas.style.top = video.offsetTop + 'px';
      canvas.style.left = video.offsetLeft + 'px';
      canvas.style.zIndex = 10;
      document.body.appendChild(canvas);

      const displaySize = { width: video.width, height: video.height };
      faceapi.matchDimensions(canvas, displaySize);

      setInterval(async () => {
        const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions());
        const resizedDetections = faceapi.resizeResults(detections, displaySize);
        const ctx = canvas.getContext('2d');
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        faceapi.draw.drawDetections(canvas, resizedDetections);
      }, 500);

      document.addEventListener('keydown', async (e) => {
        if (e.key === 'Enter') {
          const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions());
          if (detections.length === 0) {
            alert("KhÃ´ng cÃ³ khuÃ´n máº·t nÃ o!");
            return;
          }

          const randomIndex = Math.floor(Math.random() * detections.length);
          const faceBox = detections[randomIndex].box;

          const tempCanvas = document.createElement('canvas');
          tempCanvas.width = faceBox.width;
          tempCanvas.height = faceBox.height;
          const ctx = tempCanvas.getContext('2d');

          ctx.drawImage(
            video,
            faceBox.x, faceBox.y, faceBox.width, faceBox.height,
            0, 0, faceBox.width, faceBox.height
          );

          const faceImg = new Image();
          faceImg.src = tempCanvas.toDataURL();
          faceImg.className = 'face-image';
          document.body.appendChild(faceImg);
        }
      });
    }

    startBtn.onclick = async () => {
      await setupCamera();
      await startRecognition();
    };
  </script>
</body>
</html>
